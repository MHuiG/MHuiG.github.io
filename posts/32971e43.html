<!DOCTYPE html><html lang="zh-CN"><head hexo-theme="https://github.com/volantis-x/hexo-theme-volantis/tree/4.0.0"><meta charset="utf-8"><meta name="renderer" content="webkit"><meta name="force-rendering" content="webkit"><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="HandheldFriendly" content="True"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="preload" href="/css/style.css" as="style"><link rel="preload" href="/js/app.js" as="script"><link rel="preload" href="https://cdn.jsdelivr.net/npm/darkmode-js@1.5/lib/darkmode-js.min.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><title>Spark RDD编程 - MHuiG</title><meta name="keywords" content="spark"><meta name="description" content="Spark RDD 编程"><link rel="alternate" href="/atom.xml" title="MHuiG" type="application/atom+xml"><meta name="theme-color" content="skyblue"><link rel="shortcut icon" type="image/x-icon" sizes="16x16 32x32 48x48 64x64" href="https://cdn.jsdelivr.net/npm/mhg@0.0.0/favicon/favicon.ico"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="https://cdn.jsdelivr.net/npm/mhg@0.0.0/favicon/favicon_180.png"><link rel="mask-icon" color="#1BC3FB" href="https://cdn.jsdelivr.net/npm/mhg@0.0.0/favicon/favicon_180.png"><link rel="stylesheet" href="/css/style.css"><script>setTimeout(function(){window.ga_tid="UA-148909894-1",function(){var e=document.createElement("script");e.src="https://rmt.dogedoge.com/fetch/public/ga.js";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()},5e3);</script><script>var _hmt=_hmt||[];setTimeout(function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?d367964cbb21775bfbb9c16fe4da3484",e.defer=!0;var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)},5e3);</script><script>function loadScript(e,t){var n=document.getElementsByTagName("head")[0]||document.documentElement,r=document.createElement("script");r.setAttribute("type","text/javascript"),t&&(r.onload=t),r.setAttribute("src",e),n.appendChild(r)}var loadCSS=function(e,t,n,r){var i,o,a=window.document,d=a.createElement("link");o=t||(i=(a.body||a.getElementsByTagName("head")[0]).childNodes)[i.length-1];var l=a.styleSheets;if(r)for(var s in r)r.hasOwnProperty(s)&&d.setAttribute(s,r[s]);d.rel="stylesheet",d.href=e,d.media="only x",function e(t){if(a.body)return t();setTimeout(function(){e(t)})}(function(){o.parentNode.insertBefore(d,t?o:o.nextSibling)});function c(){d.addEventListener&&d.removeEventListener("load",c),d.media=n||"all"}return d.addEventListener&&d.addEventListener("load",c),(d.onloadcssdefined=function e(t){for(var n=d.href,r=l.length;r--;)if(l[r].href===n)return t();setTimeout(function(){e(t)})})(c),d};</script><script id="loadcss"></script><script type="text/javascript">function getClientHeight(){return document.body.clientHeight&&document.documentElement.clientHeight?document.body.clientHeight<document.documentElement.clientHeight?document.body.clientHeight:document.documentElement.clientHeight:document.body.clientHeight>document.documentElement.clientHeight?document.body.clientHeight:document.documentElement.clientHeight}function supportCss3(e){function t(e){return e.replace(/-(\w)/g,function(e,t){return t.toUpperCase()})}var o,n=["webkit","Moz","ms","o"],d=[],r=document.documentElement.style;for(o in n)d.push(t(n[o]+"-"+e));for(o in d.push(t(e)),d)if(d[o]in r)return!0;return!1}var options={bottom:"32px",right:"unset",left:"16px",time:"0s",mixColor:"skyblue",backgroundColor:"skyblue",buttonColorDark:"#333",buttonColorLight:"#ddd",saveInCookies:!0,label:"",autoMatchOsTheme:!0};function pjax_darkmodejs(){var e;supportCss3("mix-blend-mode")&&(e=setInterval(function(){var t;"undefined"!=typeof jQuery&&(clearInterval(e),t=getClientHeight(),$(window).scroll(function(){var e=$(document).scrollTop();t<e?($(".darkmode-layer").css("mix-blend-mode","normal"),$(".darkmode-layer").css("background-color","#21232F")):($(".darkmode-layer").css("mix-blend-mode","difference"),$(".darkmode-layer").css("background-color",""))}))},100))}function loaddarkmodejs(){supportCss3("mix-blend-mode")&&(window.darkmode=new Darkmode(options),pjax_darkmodejs())}loadScript("https://cdn.jsdelivr.net/npm/darkmode-js@1.5/lib/darkmode-js.min.js",loaddarkmodejs);</script><script>"mhuig.github.io"==window.location.host||"localhost:4000"==window.location.host||/mhuig\.top$/.test(window.location.host)||(window.location.host="blog.mhuig.top:443");</script></head><body><header class="l_header auto shadow floatable blur" style="opacity:0"><div class="container"><div class="wrapper"><div class="nav-sub"><p class="title"></p><ul class="switcher nav-list-h m-phone" id="pjax-header-nav-list"><li><a class="s-comment fad fa-comments fa-fw" target="_self" href="javascript:void(0)"></a></li><li><a class="s-toc fad fa-list fa-fw" target="_self" href="javascript:void(0)"></a></li></ul></div><div class="nav-main"> <a class="title flat-box" target="_self" href="/">MHuiG's Blog</a><div class="menu navigation"><ul class="nav-list-h m-pc"><li><a class="menuitem flat-box faa-parent animated-hover" href="/archives/" id="archives"><i class="fad fa-list-alt fa-fw"></i> 索引</a><ul class="list-v"><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/" id="categories"><i class="fad fa-folder-open fa-fw"></i> 分类</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/tags/" id="tags"><i class="fad fa-tags fa-fw"></i> 标签</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/archives/" id="archives"><i class="fad fa-archive fa-fw"></i> 归档</a></li></ul></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/friends/" id="friends"><i class="fad fa-link fa-fw"></i> 友链</a><ul class="list-v"><li class="header"><i class="fad fa-share fa-fw"></i> 友链接力</li><li><a class="menuitem flat-box faa-parent animated-hover" href="https://travellings.now.sh/" id="https:travellingsnowsh" rel="external nofollow noopener noreferrer" target="_blank"><i class="fad fa-paper-plane fa-fw"></i> Travelling</a></li></ul></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/about/" id="about"><i class="fad fa-user-tie fa-fw"></i> 关于</a><ul class="list-v"><li><a class="menuitem flat-box faa-parent animated-hover" href="/time-machine/" id="time-machine"><i class="fad fa-clock fa-fw"></i> 时光机</a></li></ul></li><li><a class="menuitem flat-box faa-parent animated-hover"><i class="fad fa-fan fa-spin fa-fw"></i> 更多</a><ul class="list-v"><li><a class="menuitem flat-box faa-parent animated-hover"><i class="fad fa-user-shield fa-fw"></i> 博客管理</a><ul class="list-v"><li><a class="menuitem flat-box faa-parent animated-hover" href="https://inf.mhuig.top" id="https:infmhuigtop" rel="external nofollow noopener noreferrer" target="_blank"><i class="fad fa-comments fa-fw"></i> 评论管理</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="https://www.yuque.com/mhuig" id="https:wwwyuquecommhuig" rel="external nofollow noopener noreferrer" target="_blank"><i class="fad fa-edit fa-fw"></i> 云端编辑</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="https://status.mhuig.top/" id="https:statusmhuigtop" rel="external nofollow noopener noreferrer" target="_blank"><i class="fad fa-telescope fa-fw"></i> Monitors</a></li></ul></li><hr><li><a class="menuitem flat-box faa-parent animated-hover"><i class="fad fa-tools fa-fw"></i> 工具箱</a><ul class="list-v"><li class="header"><i class="fad fa-moon darkbtn fa-fw"></i> Dark Mode</li><li><a class="menuitem flat-box"><i class="fad fa-compact-disc fa-spin fa-fw music"></i> Music</a><ul class="list-v"><li><div class="aplayer-container"><meting-js theme="#1BCDFC" volume="0.7" loop="all" order="list" fixed="false" list-max-height="320px" server="netease" type="song" id="412785957" list-folded="true"></meting-js></div></li></ul></li><li></li><li><a class="menuitem flat-box faa-parent animated-hover" href="https://MHuiG.github.io/NoteBook/" id="https:MHuiGgithubioNoteBook"><i class="fad fa-star fa-spin fa-fw"></i> NoteBook</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/atom.xml" id="atomxml"><i class="fad fa-rss fa-fw"></i> RSS订阅</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/sitemap.xml" id="sitemapxml"><i class="fad fa-sitemap fa-fw"></i> 站点地图</a></li></ul></li><hr><li><a class="menuitem flat-box faa-parent animated-hover" href="https://github.com/MHuiG" id="https:githubcomMHuiG" rel="external nofollow noopener noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></li></ul></li></ul></div><div class="m_search"><form name="searchform" class="form u-search-form"><i class="icon fad fa-search fa-fw"></i> <input type="text" class="input u-search-input" placeholder="Search..."></form></div><ul class="switcher nav-list-h m-phone"><li><a class="s-search fad fa-search fa-fw" target="_self" href="javascript:void(0)"></a></li><li><a class="s-menu fad fa-bars fa-fw" target="_self" href="javascript:void(0)"></a><ul class="menu-phone list-v navigation white-box"><li><a class="menuitem flat-box faa-parent animated-hover" href="/archives/" id="archives"><i class="fad fa-list-alt fa-fw"></i> 索引</a><ul class="list-v"><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/" id="categories"><i class="fad fa-folder-open fa-fw"></i> 分类</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/tags/" id="tags"><i class="fad fa-tags fa-fw"></i> 标签</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/archives/" id="archives"><i class="fad fa-archive fa-fw"></i> 归档</a></li></ul></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/friends/" id="friends"><i class="fad fa-link fa-fw"></i> 友链</a><ul class="list-v"><li class="header"><i class="fad fa-share fa-fw"></i> 友链接力</li><li><a class="menuitem flat-box faa-parent animated-hover" href="https://travellings.now.sh/" id="https:travellingsnowsh" rel="external nofollow noopener noreferrer" target="_blank"><i class="fad fa-paper-plane fa-fw"></i> Travelling</a></li></ul></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/about/" id="about"><i class="fad fa-user-tie fa-fw"></i> 关于</a><ul class="list-v"><li><a class="menuitem flat-box faa-parent animated-hover" href="/time-machine/" id="time-machine"><i class="fad fa-clock fa-fw"></i> 时光机</a></li></ul></li><li><a class="menuitem flat-box faa-parent animated-hover"><i class="fad fa-fan fa-spin fa-fw"></i> 更多</a><ul class="list-v"><li><a class="menuitem flat-box faa-parent animated-hover"><i class="fad fa-user-shield fa-fw"></i> 博客管理</a><ul class="list-v"><li><a class="menuitem flat-box faa-parent animated-hover" href="https://inf.mhuig.top" id="https:infmhuigtop" rel="external nofollow noopener noreferrer" target="_blank"><i class="fad fa-comments fa-fw"></i> 评论管理</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="https://www.yuque.com/mhuig" id="https:wwwyuquecommhuig" rel="external nofollow noopener noreferrer" target="_blank"><i class="fad fa-edit fa-fw"></i> 云端编辑</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="https://status.mhuig.top/" id="https:statusmhuigtop" rel="external nofollow noopener noreferrer" target="_blank"><i class="fad fa-telescope fa-fw"></i> Monitors</a></li></ul></li><hr><li><a class="menuitem flat-box faa-parent animated-hover"><i class="fad fa-tools fa-fw"></i> 工具箱</a><ul class="list-v"><li class="header"><i class="fad fa-moon darkbtn fa-fw"></i> Dark Mode</li><li><a class="menuitem flat-box faa-parent animated-hover" href="https://MHuiG.github.io/NoteBook/" id="https:MHuiGgithubioNoteBook"><i class="fad fa-star fa-spin fa-fw"></i> NoteBook</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/atom.xml" id="atomxml"><i class="fad fa-rss fa-fw"></i> RSS订阅</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/sitemap.xml" id="sitemapxml"><i class="fad fa-sitemap fa-fw"></i> 站点地图</a></li></ul></li><hr><li><a class="menuitem flat-box faa-parent animated-hover" href="https://github.com/MHuiG" id="https:githubcomMHuiG" rel="external nofollow noopener noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></li></ul></li></ul></li></ul></div></div></div></header><div class="l_body"><div class="l_cover"><div class="cover-wrapper post featured" style="display:none"><div class="cover-backstretch"></div><div class="cover-body"><div class="top"><p class="title">MHuiG</p><p class="subtitle">「Be Yourself, Make a Difference.」</p></div><div class="bottom"><div class="menu navigation"><div class="list-h"><a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/MHuiG" id="https:githubcomMHuiG"><i class="fab fa-github fa-fw" style="color:#000"></i><p>Github</p></a><a href="/friends/" id="friends"><i class="fad fa-link fa-fw" style="color:#d31ee9"></i><p>友链</p></a><a href="/about/" id="about"><i class="fad fa-user-tie fa-fw" style="color:#0095ff"></i><p>关于</p></a><a target="_blank" rel="external nofollow noopener noreferrer" href="https://travellings.now.sh/" id="https:travellingsnowsh"><i class="fad fa-paper-plane fa-fw" style="color:#734ae6"></i><p>Travelling</p></a></div></div></div></div><div class="scroll-down" style="display:none"><i class="fa fa-chevron-down scroll-down-effects"></i></div></div></div><div class="safearea"><div class="body-wrapper" id="pjax-container"><div id="pjax-data" style="display:none"><div id="pjax-ispage">true</div><div id="pjax-pageTitle">Spark RDD编程</div><div id="pjax-enable-cover">true</div><div id="pjax-comment-path"></div><div id="pjax-comment-placeholder"></div></div><script>document.getElementsByClassName("cover-wrapper")[0].style.display="none",document.getElementsByClassName("l_header","cover-wrapper")[0].classList.add("show");</script><div class="l_main"><article class="article post white-box reveal md shadow floatable blur article-type-post" id="post" itemscope itemprop="blogPost"><div class="article-meta" id="top"><h1 class="title"> Spark RDD编程</h1><div class="new-meta-box"><div class="new-meta-item category"><a class="notlink"><i class="fad fa-folder-open fa-fw" aria-hidden="true"></i> <a class="category-link" href="/categories/spark/">spark</a></a></div><div class="new-meta-item date"><a class="notlink"><i class="fad fa-calendar-alt fa-fw" aria-hidden="true"></i><p>发布于：2020年5月20日</p></a></div><div class="new-meta-item wordcount"><a class="notlink"><i class="fad fa-keyboard fa-fw" aria-hidden="true"></i><p>字数：2.4k字</p></a></div><div class="new-meta-item readtime"><a class="notlink"><i class="fad fa-hourglass-half fa-fw" aria-hidden="true"></i><p>时长：11分钟</p></a></div></div></div><p>Spark RDD 编程</p><a id="more"></a><h2 id="RDD-编程基础"><a href="#RDD-编程基础" class="headerlink" title="RDD 编程基础"></a><strong>RDD 编程基础</strong></h2><h3 id="RDD-创建"><a href="#RDD-创建" class="headerlink" title="RDD 创建"></a>RDD 创建</h3><h4 id="从文件系统中加载数据创建-RDD"><a href="#从文件系统中加载数据创建-RDD" class="headerlink" title="从文件系统中加载数据创建 RDD"></a><strong>从文件系统中加载数据创建 RDD</strong></h4><p>Spark 采用 textFile()方法来从文件系统中加载数据创建 RDD<br>该方法把文件的 URI 作为参数，这个 URI 可以是</p><ul><li>本地文件系统的地址</li><li>分布式文件系统 HDFS 的地址</li><li>AmazonS3 的地址</li><li>等等</li></ul><h5 id="从本地文件系统中加载数据创建-RDD"><a href="#从本地文件系统中加载数据创建-RDD" class="headerlink" title="从本地文件系统中加载数据创建 RDD"></a>从本地文件系统中加载数据创建 RDD</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; lines = sc.textFile(<span class="string">&quot;file:///usr/local/spark/mycode/rdd/word.txt&quot;</span>)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; lines.foreach(<span class="built_in">print</span>)</span></span><br><span class="line">Hadoop is good</span><br><span class="line">Spark is fast</span><br><span class="line">Spark is better</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/20200520155222.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/20200520155222.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><h5 id="从分布式文件系统-HDFS-中加载数据"><a href="#从分布式文件系统-HDFS-中加载数据" class="headerlink" title="从分布式文件系统 HDFS 中加载数据"></a>从分布式文件系统 HDFS 中加载数据</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; lines = sc.textFile(<span class="string">&quot;hdfs://localhost:9000/user/hadoop/word.txt&quot;</span>)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; lines = sc.textFile(<span class="string">&quot;/user/hadoop/word.txt&quot;</span>)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; lines = sc.textFile(<span class="string">&quot;word.txt&quot;</span>)</span></span><br></pre></td></tr></table></figure><h4 id="通过并行集合（列表）创建-RDD"><a href="#通过并行集合（列表）创建-RDD" class="headerlink" title="通过并行集合（列表）创建 RDD"></a><strong>通过并行集合（列表）创建 RDD</strong></h4><p>可以调用 SparkContext 的 parallelize 方法，在 Driver 中一个已经存在的集合（列表）上创建。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; array = [1,2,3,4,5]</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd = sc.parallelize(array)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd.foreach(<span class="built_in">print</span>)</span></span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/20200520155945.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/20200520155945.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><h3 id="RDD-操作"><a href="#RDD-操作" class="headerlink" title="RDD 操作"></a>RDD 操作</h3><h4 id="转换操作"><a href="#转换操作" class="headerlink" title="转换操作"></a><strong>转换操作</strong></h4><p>对于 RDD 而言，每一次转换操作都会产生不同的 RDD，供给下一个“转换”使用.<br>转换得到的 RDD 是惰性求值的，也就是说，整个转换过程只是记录了转换的轨迹，并不会发生真正的计算，只有遇到行动操作时，才会发生真正的计算，开始从血缘关系源头开始，进行物理的转换操作.</p><table><thead><tr><th><strong>操作</strong></th><th><strong>含义</strong></th></tr></thead><tbody><tr><td>filter(func)</td><td>筛选出满足函数 func 的元素，并返回一个新的数据集</td></tr><tr><td>map(func)</td><td>将每个元素传递到函数 func 中，并将结果返回为一个新的数据集</td></tr><tr><td>flatMap(func)</td><td>与 map()相似，但每个输入元素都可以映射到 0 或多个输出结果</td></tr><tr><td>groupByKey()</td><td>应用于(K,V)键值对的数据集时，返回一个新的(K,Iterable)形式的数据集</td></tr><tr><td>reduceByKey(func)</td><td>应用于(K,V)键值对的数据集时，返回一个新的(K,V)形式的数据集，其中每个值是将每个 key 传递到函数 func 中进行聚合后的结果</td></tr></tbody></table><h5 id="filter-func"><a href="#filter-func" class="headerlink" title="filter(func)"></a>filter(func)</h5><p>筛选出满足函数 func 的元素，并返回一个新的数据集</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt;  lines = sc.textFile(<span class="string">&quot;file:///usr/local/spark/mycode/rdd/word.txt&quot;</span>)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt;  linesWithSpark = lines.filter(lambda line: <span class="string">&quot;Spark&quot;</span> <span class="keyword">in</span> line)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; linesWithSpark.foreach(<span class="built_in">print</span>)</span></span><br><span class="line">Spark is better</span><br><span class="line">Spark is fast</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/20200520160903.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/20200520160903.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><h5 id="map-func"><a href="#map-func" class="headerlink" title="map(func)"></a>map(func)</h5><p>map(func)操作将每个元素传递到函数 func 中，并将结果返回为一个新的数据集</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; data = [1,2,3,4,5]</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1 = sc.parallelize(data)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2 = rdd1.map(lambda x:x+10)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2.foreach(<span class="built_in">print</span>)</span></span><br><span class="line">11</span><br><span class="line">13</span><br><span class="line">12</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/20200520161243.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/20200520161243.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><h4 id="flatMap-func"><a href="#flatMap-func" class="headerlink" title="flatMap(func)"></a>flatMap(func)</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; lines = sc.textFile(<span class="string">&quot;file:///usr/local/spark/mycode/rdd/word.txt&quot;</span>)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; words = lines.flatMap(lambda line:line.split(<span class="string">&quot; &quot;</span>))</span></span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/20200520161713.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/20200520161713.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><h4 id="groupByKey"><a href="#groupByKey" class="headerlink" title="groupByKey()"></a>groupByKey()</h4><p>应用于(K,V)键值对的数据集时，返回一个新的(K, Iterable)形式的数据集</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; words = sc.parallelize([(<span class="string">&quot;Hadoop&quot;</span>,1),(<span class="string">&quot;is&quot;</span>,1),(<span class="string">&quot;good&quot;</span>,1), \</span></span><br><span class="line">... (&quot;Spark&quot;,1),(&quot;is&quot;,1),(&quot;fast&quot;,1),(&quot;Spark&quot;,1),(&quot;is&quot;,1),(&quot;better&quot;,1)])</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; words1 = words.groupByKey()</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; words1.foreach(<span class="built_in">print</span>)</span></span><br><span class="line">(&#x27;Hadoop&#x27;, &lt;pyspark.resultiterable.ResultIterable object at 0x7fb210552c88&gt;)</span><br><span class="line">(&#x27;better&#x27;, &lt;pyspark.resultiterable.ResultIterable object at 0x7fb210552e80&gt;)</span><br><span class="line">(&#x27;fast&#x27;, &lt;pyspark.resultiterable.ResultIterable object at 0x7fb210552c88&gt;)</span><br><span class="line">(&#x27;good&#x27;, &lt;pyspark.resultiterable.ResultIterable object at 0x7fb210552c88&gt;)</span><br><span class="line">(&#x27;Spark&#x27;, &lt;pyspark.resultiterable.ResultIterable object at 0x7fb210552f98&gt;)</span><br><span class="line">(&#x27;is&#x27;, &lt;pyspark.resultiterable.ResultIterable object at 0x7fb210552e10&gt;)</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/20200520161927.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/20200520161927.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><h4 id="reduceByKey-func"><a href="#reduceByKey-func" class="headerlink" title="reduceByKey(func)"></a>reduceByKey(func)</h4><p>应用于(K,V)键值对的数据集时，返回一个新的(K, V)形式的数据集，其中的每个值是将每个 key 传递到函数 func 中进行聚合后得到的结果</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; words = sc.parallelize([(<span class="string">&quot;Hadoop&quot;</span>,1),(<span class="string">&quot;is&quot;</span>,1),(<span class="string">&quot;good&quot;</span>,1),(<span class="string">&quot;Spark&quot;</span>,1), \</span></span><br><span class="line">... (&quot;is&quot;,1),(&quot;fast&quot;,1),(&quot;Spark&quot;,1),(&quot;is&quot;,1),(&quot;better&quot;,1)])</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; words1 = words.reduceByKey(lambda a,b:a+b)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; words1.foreach(<span class="built_in">print</span>)</span></span><br><span class="line"> (&#x27;good&#x27;, 1)</span><br><span class="line">(&#x27;Hadoop&#x27;, 1)</span><br><span class="line">(&#x27;better&#x27;, 1)</span><br><span class="line">(&#x27;Spark&#x27;, 2)</span><br><span class="line">(&#x27;fast&#x27;, 1)</span><br><span class="line">(&#x27;is&#x27;, 3)</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/20200520162110.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/20200520162110.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><h4 id="行动操作"><a href="#行动操作" class="headerlink" title="行动操作"></a><strong>行动操作</strong></h4><p>行动操作是真正触发计算的地方。Spark 程序执行到行动操作时，才会执行真正的计算，从文件中加载数据，完成一次又一次转换操作，最终，完成行动操作得到结果。</p><table><thead><tr><th><strong>操作</strong></th><th><strong>含义</strong></th></tr></thead><tbody><tr><td>count()</td><td>返回数据集中的元素个数</td></tr><tr><td>collect()</td><td>以数组的形式返回数据集中的所有元素</td></tr><tr><td>first()</td><td>返回数据集中的第一个元素</td></tr><tr><td>take(n)</td><td>以数组的形式返回数据集中的前 n 个元素</td></tr><tr><td>reduce(func)</td><td>通过函数 func（输入两个参数并返回一个值）聚合数据集中的元素</td></tr><tr><td>foreach(func)</td><td>将数据集中的每个元素传递到函数 func 中运行</td></tr></tbody></table><h4 id="惰性机制"><a href="#惰性机制" class="headerlink" title="惰性机制"></a><strong>惰性机制</strong></h4><p>所谓的“惰性机制”是指，整个转换过程只是记录了转换的轨迹，并不会发生真正的计算，只有遇到行动操作时，才会触发“从头到尾”的真正的计算<br>这里给出一段简单的语句来解释 Spark 的惰性机制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; lines = sc.textFile(<span class="string">&quot;file:///usr/local/spark/mycode/rdd/word.txt&quot;</span>)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; lineLengths = lines.map(lambda s:len(s))</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; totalLength = lineLengths.reduce(lambda a,b:a+b)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; <span class="built_in">print</span>(totalLength)</span></span><br></pre></td></tr></table></figure><h3 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h3><p>在 Spark 中，RDD 采用惰性求值的机制，每次遇到行动操作，都会从头开始执行计算。每次调用行动操作，都会触发一次从头开始的计算。这对于迭代计算而言，代价是很大的，迭代计算经常需要多次重复使用同一组数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; list = [<span class="string">&quot;Hadoop&quot;</span>,<span class="string">&quot;Spark&quot;</span>,<span class="string">&quot;Hive&quot;</span>]</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd = sc.parallelize(list)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; <span class="built_in">print</span>(rdd.count()) //行动操作，触发一次真正从头到尾的计算</span></span><br><span class="line">3</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; <span class="built_in">print</span>(<span class="string">&#x27;,&#x27;</span>.join(rdd.collect())) //行动操作，触发一次真正从头到尾的计算</span></span><br><span class="line">Hadoop,Spark,Hive</span><br></pre></td></tr></table></figure><ul><li>可以通过持久化（缓存）机制避免这种重复计算的开销</li><li>可以使用 persist()方法对一个 RDD 标记为持久化</li><li>之所以说“标记为持久化”，是因为出现 persist()语句的地方，并不会马上计算生成 RDD 并把它持久化，而是要等到遇到第一个行动操作触发真正计算以后，才会把计算结果进行持久化</li><li>持久化后的 RDD 将会被保留在计算节点的内存中被后面的行动操作重复使用</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; list = [<span class="string">&quot;Hadoop&quot;</span>,<span class="string">&quot;Spark&quot;</span>,<span class="string">&quot;Hive&quot;</span>]</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd = sc.parallelize(list)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd.cache()  <span class="comment">#会调用persist(MEMORY_ONLY)，但是，语句执行到这里，并不会缓存rdd，因为这时rdd还没有被计算生成</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; <span class="built_in">print</span>(rdd.count()) <span class="comment">#第一次行动操作，触发一次真正从头到尾的计算，这时上面的rdd.cache()才会被执行，把这个rdd放到缓存中</span></span></span><br><span class="line">3</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; <span class="built_in">print</span>(<span class="string">&#x27;,&#x27;</span>.join(rdd.collect())) <span class="comment">#第二次行动操作，不需要触发从头到尾的计算，只需要重复使用上面缓存中的rdd</span></span></span><br><span class="line">Hadoop,Spark,Hive</span><br></pre></td></tr></table></figure><h3 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h3><p>RDD 是弹性分布式数据集，通常 RDD 很大，会被分成很多个分区，分别保存在不同的节点上<br>RDD 分区的一个原则是使得分区的个数尽量等于集群中的 CPU 核心（core）数目</p><h2 id="键值对-RDD"><a href="#键值对-RDD" class="headerlink" title="键值对 RDD"></a><strong>键值对 RDD</strong></h2><h3 id="键值对-RDD-的创建"><a href="#键值对-RDD-的创建" class="headerlink" title="键值对 RDD 的创建"></a>键值对 RDD 的创建</h3><h4 id="从文件中加载"><a href="#从文件中加载" class="headerlink" title="从文件中加载"></a><strong>从文件中加载</strong></h4><p>可以采用多种方式创建键值对 RDD，其中一种主要方式是使用 map()函数来实现</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; lines = sc.textFile(<span class="string">&quot;file:///usr/local/spark/mycode/pairrdd/word.txt&quot;</span>)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; pairRDD = lines.flatMap(lambda line:line.split(<span class="string">&quot; &quot;</span>)).map(lambda word:(word,1))</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; pairRDD.foreach(<span class="built_in">print</span>)</span></span><br><span class="line">(&#x27;I&#x27;, 1)</span><br><span class="line">(&#x27;love&#x27;, 1)</span><br><span class="line">(&#x27;Hadoop&#x27;, 1)</span><br><span class="line">……</span><br></pre></td></tr></table></figure><h4 id="通过并行集合（列表）创建-RDD-1"><a href="#通过并行集合（列表）创建-RDD-1" class="headerlink" title="通过并行集合（列表）创建 RDD"></a><strong>通过并行集合（列表）创建 RDD</strong></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; list = [<span class="string">&quot;Hadoop&quot;</span>,<span class="string">&quot;Spark&quot;</span>,<span class="string">&quot;Hive&quot;</span>,<span class="string">&quot;Spark&quot;</span>]</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd = sc.parallelize(list)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; pairRDD = rdd.map(lambda word:(word,1))</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; pairRDD.foreach(<span class="built_in">print</span>)</span></span><br><span class="line">(Hadoop,1)</span><br><span class="line">(Spark,1)</span><br><span class="line">(Hive,1)</span><br><span class="line">(Spark,1)</span><br></pre></td></tr></table></figure><h3 id="常用的键值对-RDD-转换操作"><a href="#常用的键值对-RDD-转换操作" class="headerlink" title="常用的键值对 RDD 转换操作"></a>常用的键值对 RDD 转换操作</h3><h4 id="reduceByKey-func-1"><a href="#reduceByKey-func-1" class="headerlink" title="reduceByKey(func)"></a><strong>reduceByKey(func)</strong></h4><p>使用 func 函数合并具有相同键的值</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; pairRDD = sc.parallelize([(<span class="string">&quot;Hadoop&quot;</span>,1),(<span class="string">&quot;Spark&quot;</span>,1),(<span class="string">&quot;Hive&quot;</span>,1),(<span class="string">&quot;Spark&quot;</span>,1)])</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; pairRDD.reduceByKey(lambda a,b:a+b).foreach(<span class="built_in">print</span>)</span></span><br><span class="line">(&#x27;Spark&#x27;, 2)</span><br><span class="line">(&#x27;Hive&#x27;, 1)</span><br><span class="line">(&#x27;Hadoop&#x27;, 1)</span><br></pre></td></tr></table></figure><h4 id="groupByKey-1"><a href="#groupByKey-1" class="headerlink" title="groupByKey()"></a>groupByKey()</h4><p>对具有相同键的值进行分组</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; list = [(<span class="string">&quot;spark&quot;</span>,1),(<span class="string">&quot;spark&quot;</span>,2),(<span class="string">&quot;hadoop&quot;</span>,3),(<span class="string">&quot;hadoop&quot;</span>,5)]</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; pairRDD = sc.parallelize(list)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; pairRDD.groupByKey()</span></span><br><span class="line">PythonRDD[27] at RDD at PythonRDD.scala:48</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; pairRDD.groupByKey().foreach(<span class="built_in">print</span>)</span></span><br><span class="line">(&#x27;hadoop&#x27;, &lt;pyspark.resultiterable.ResultIterable object at 0x7f2c1093ecf8&gt;)</span><br><span class="line">(&#x27;spark&#x27;, &lt;pyspark.resultiterable.ResultIterable object at 0x7f2c1093ecf8&gt;)</span><br></pre></td></tr></table></figure><h4 id="sortByKey"><a href="#sortByKey" class="headerlink" title="sortByKey()"></a>sortByKey()</h4><p>返回一个根据键排序的 RDD</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; list = [(<span class="string">&quot;Hadoop&quot;</span>,1),(<span class="string">&quot;Spark&quot;</span>,1),(<span class="string">&quot;Hive&quot;</span>,1),(<span class="string">&quot;Spark&quot;</span>,1)]</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; pairRDD = sc.parallelize(list)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; pairRDD.foreach(<span class="built_in">print</span>)</span></span><br><span class="line">(&#x27;Hadoop&#x27;, 1)</span><br><span class="line">(&#x27;Spark&#x27;, 1)</span><br><span class="line">(&#x27;Hive&#x27;, 1)</span><br><span class="line">(&#x27;Spark&#x27;, 1)</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; pairRDD.sortByKey().foreach(<span class="built_in">print</span>)</span></span><br><span class="line">(&#x27;Hadoop&#x27;, 1)</span><br><span class="line">(&#x27;Hive&#x27;, 1)</span><br><span class="line">(&#x27;Spark&#x27;, 1)</span><br><span class="line">(&#x27;Spark&#x27;, 1)</span><br></pre></td></tr></table></figure><h4 id="mapValues-func"><a href="#mapValues-func" class="headerlink" title="mapValues(func)"></a><strong>mapValues(func)</strong></h4><p>对键值对 RDD 中的每个 value 都应用一个函数，但是，key 不会发生变化</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; list = [(<span class="string">&quot;Hadoop&quot;</span>,1),(<span class="string">&quot;Spark&quot;</span>,1),(<span class="string">&quot;Hive&quot;</span>,1),(<span class="string">&quot;Spark&quot;</span>,1)]</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; pairRDD = sc.parallelize(list)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; pairRDD1 = pairRDD.mapValues(lambda x:x+1)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; pairRDD1.foreach(<span class="built_in">print</span>)</span></span><br><span class="line">(&#x27;Hadoop&#x27;, 2)</span><br><span class="line">(&#x27;Spark&#x27;, 2)</span><br><span class="line">(&#x27;Hive&#x27;, 2)</span><br><span class="line">(&#x27;Spark&#x27;, 2)</span><br></pre></td></tr></table></figure><h4 id="join"><a href="#join" class="headerlink" title="join"></a>join</h4><p>join 就表示内连接。对于内连接，对于给定的两个输入数据集(K,V1)和(K,V2)，只有在两个数据集中都存在的 key 才会被输出，最终得到一个(K,(V1,V2))类型的数据集。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; pairRDD1 = sc. \</span></span><br><span class="line">... parallelize([(&quot;spark&quot;,1),(&quot;spark&quot;,2),(&quot;hadoop&quot;,3),(&quot;hadoop&quot;,5)])</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; pairRDD2 = sc.parallelize([(<span class="string">&quot;spark&quot;</span>,<span class="string">&quot;fast&quot;</span>)])</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; pairRDD3 = pairRDD1.join(pairRDD2)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; pairRDD3.foreach(<span class="built_in">print</span>)</span></span><br><span class="line">(&#x27;spark&#x27;, (1, &#x27;fast&#x27;))</span><br><span class="line">(&#x27;spark&#x27;, (2, &#x27;fast&#x27;))</span><br></pre></td></tr></table></figure><div class="footer"><div class="copyright"><blockquote><p>博客内容遵循 署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</p><p>本文永久链接是：<a href="https://mhuig.github.io/posts/32971e43.html">https://mhuig.github.io/posts/32971e43.html</a></p></blockquote></div></div><div class="article-meta" id="bottom"><div class="new-meta-box"><div class="new-meta-item date" itemprop="dateUpdated" datetime="2020-05-20T15:45:29+08:00"><a class="notlink"><i class="fad fa-edit fa-fw" aria-hidden="true"></i><p>更新于：2020年5月20日</p></a></div><div class="new-meta-item browse valine"><a class="notlink"><i class="fad fa-eye fa-fw" aria-hidden="true"></i><span id="/posts/32971e43.html" class="leancloud_visitors" data-flag-title="Spark RDD编程"><p><span class="leancloud-visitors-count"></span></p></span></a></div><div class="new-meta-item meta-tags"><a class="tag" href="/tags/spark/" rel="nofollow"><i class="fad fa-hashtag fa-fw" aria-hidden="true"></i><p>spark</p></a></div></div></div><div class="prev-next"><a class="prev" href="/posts/1e621a56.html"><p class="title"><i class="fad fa-chevron-left" aria-hidden="true"></i>基于Audioscrobbler数据集的音乐推荐(pyspark)</p><p class="content">根据用户播放次数数据使用协同过滤算法完成音乐推荐。 数据集Audioscrobbler数据集 下载 Audioscrobbler 数据集 user_artist_data.txt它包含14...</p></a><a class="next" href="/posts/e846a0cc.html"><p class="title">Spark环境部署（Ubuntu20.04）<i class="fad fa-chevron-right" aria-hidden="true"></i></p><p class="content">Spark  在 Ubuntu20.04 中的配置 实验环境 实验环境 Ubuntu20.04 LTSHadoop 2.6.0-c...</p></a></div></article><article class="post white-box reveal shadow floatable blur" id="comments"><p ct><i class="fad fa-comments"></i> 评论</p><div id="minivaline_container"><i class="fad fa-cog fa-spin fa-fw fa-2x"></i></div></article></div><aside class="l_side"><section class="widget toc-wrapper shadow floatable blur desktop mobile" id="toc-div"><header><i class="fad fa-list fa-fw" aria-hidden="true"></i> <span class="name">本文目录</span></header><div class="content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#RDD-%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80"><span class="toc-text">RDD 编程基础</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#RDD-%E5%88%9B%E5%BB%BA"><span class="toc-text">RDD 创建</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E5%88%9B%E5%BB%BA-RDD"><span class="toc-text">从文件系统中加载数据创建 RDD</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BB%8E%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E5%88%9B%E5%BB%BA-RDD"><span class="toc-text">从本地文件系统中加载数据创建 RDD</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BB%8E%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%B8%AD%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE"><span class="toc-text">从分布式文件系统 HDFS 中加载数据</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%9A%E8%BF%87%E5%B9%B6%E8%A1%8C%E9%9B%86%E5%90%88%EF%BC%88%E5%88%97%E8%A1%A8%EF%BC%89%E5%88%9B%E5%BB%BA-RDD"><span class="toc-text">通过并行集合（列表）创建 RDD</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RDD-%E6%93%8D%E4%BD%9C"><span class="toc-text">RDD 操作</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C"><span class="toc-text">转换操作</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#filter-func"><span class="toc-text">filter(func)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#map-func"><span class="toc-text">map(func)</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#flatMap-func"><span class="toc-text">flatMap(func)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#groupByKey"><span class="toc-text">groupByKey()</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#reduceByKey-func"><span class="toc-text">reduceByKey(func)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A1%8C%E5%8A%A8%E6%93%8D%E4%BD%9C"><span class="toc-text">行动操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%83%B0%E6%80%A7%E6%9C%BA%E5%88%B6"><span class="toc-text">惰性机制</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%81%E4%B9%85%E5%8C%96"><span class="toc-text">持久化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%8C%BA"><span class="toc-text">分区</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%94%AE%E5%80%BC%E5%AF%B9-RDD"><span class="toc-text">键值对 RDD</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%94%AE%E5%80%BC%E5%AF%B9-RDD-%E7%9A%84%E5%88%9B%E5%BB%BA"><span class="toc-text">键值对 RDD 的创建</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%8E%E6%96%87%E4%BB%B6%E4%B8%AD%E5%8A%A0%E8%BD%BD"><span class="toc-text">从文件中加载</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%9A%E8%BF%87%E5%B9%B6%E8%A1%8C%E9%9B%86%E5%90%88%EF%BC%88%E5%88%97%E8%A1%A8%EF%BC%89%E5%88%9B%E5%BB%BA-RDD-1"><span class="toc-text">通过并行集合（列表）创建 RDD</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E7%9A%84%E9%94%AE%E5%80%BC%E5%AF%B9-RDD-%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C"><span class="toc-text">常用的键值对 RDD 转换操作</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#reduceByKey-func-1"><span class="toc-text">reduceByKey(func)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#groupByKey-1"><span class="toc-text">groupByKey()</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#sortByKey"><span class="toc-text">sortByKey()</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#mapValues-func"><span class="toc-text">mapValues(func)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#join"><span class="toc-text">join</span></a></li></ol></li></ol></li></ol></div></section></aside></div><footer class="footer clearfix"><br><br><div class="aplayer-container"><meting-js theme="#1BCDFC" volume="0.7" loop="all" order="list" fixed="false" list-max-height="320px" server="netease" type="song" id="412785957" list-folded="true"></meting-js></div><br><div class="social-wrapper"><a href="/atom.xml" class="social fad fa-rss flat-btn" target="_blank" rel="external nofollow noopener noreferrer"></a><a href="mailto:mhuig1998@gmail.com" class="social fad fa-envelope flat-btn" target="_blank" rel="external nofollow noopener noreferrer"></a><a href="https://github.com/MHuiG" class="social fab fa-github flat-btn" target="_blank" rel="external nofollow noopener noreferrer"></a><a href="https://music.163.com/#/user/home?id=63035382" class="social fad fa-headphones-alt flat-btn" target="_blank" rel="external nofollow noopener noreferrer"></a></div><div><p>博客内容遵循 <a target="_blank" rel="external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</a></p></div><div class="copyright"><p><a href="https://icp.gov.moe" target="_blank" rel="external nofollow noopener noreferrer">萌ICP备</a> <a href="https://icp.gov.moe/?keyword=2020012138" target="_blank" rel="external nofollow noopener noreferrer">2020012138号</a><br><a href="https://mhuig.github.io/">Copyright © 2018-2020 MHuiG</a></p></div></footer><noscript><style type="text/css">#dialog{background-color:#fff;height:100%;width:100%;position:fixed!important;position:absolute;top:0;left:0;z-index:500;display:none}#dialog p{margin:0 auto;height:auto;line-height:124px;background:#ccc;color:red;font-size:60px}</style><div id="dialog" style="display:block"><div><p style="text-align:center"><b>本页面需要浏览器支持（启用）JavaScript<br><br>This page requires browser support (enabled) JavaScript</b></p></div></div></noscript><a class="s-top fad fa-arrow-up fa-fw" href="javascript:void(0)"></a></div></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@3.5/dist/jquery.min.js"></script><script>function pjax_fancybox(){$(".md .gallery").find("img").each(function(){var a=document.createElement("a");$(a).attr("class","fancybox"),$(a).attr("pjax-fancybox",""),$(a).attr("href",$(this).attr("src")),$(this).attr("data-original")&&$(a).attr("href",$(this).attr("data-original")),$(a).attr("data-fancybox","images");var t="";$(this).attr("alt")&&($(a).attr("data-caption",$(this).attr("alt")),t=$(this).attr("alt"));var n=document.createElement("div");$(n).addClass("fancybox"),$(this).wrap(n);var e=document.createElement("span");$(e).addClass("image-caption"),$(e).text(t),$(this).after(e),$(this).wrap(a)}),$(".md .gallery").find("img").fancybox({selector:'[data-fancybox="images"]',hash:!1,loop:!1,closeClick:!0,helpers:{overlay:{closeClick:!0}},buttons:["zoom","close"]})}function SCload_fancybox(){0!=$(".md .gallery").find("img").length&&(loadCSS("https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css",document.getElementById("loadcss")),setTimeout(function(){loadScript("https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js",pjax_fancybox)},1))}$(function(){SCload_fancybox()});</script><script type="text/javascript">$(function(){for(var t=[],e=1;e<=40;e++)t.push("https://cdn.jsdelivr.net/npm/mhg@0.0.0/cov/1%20("+e+").webp");!function(t){for(var e=t.length;e--;){var c=Math.floor(Math.random()*e),r=t[c];t[c]=t[e],t[e]=r}}(t),loadScript("https://cdn.jsdelivr.net/npm/jquery-backstretch@2.1.18/jquery.backstretch.min.js",function(){setTimeout(function(){$(".cover-backstretch").backstretch(t,{duration:"10000",fade:"1500"}),"none"==document.getElementsByClassName("cover-wrapper")[0].style.display?$(".cover-backstretch").backstretch("pause"):$(".cover-backstretch").backstretch("next")},1e4)})});</script><script defer="defer" src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.1.0/dist/lazyload.min.js"></script><script>window.lazyLoadOptions={elements_selector:".lazyload",threshold:0},window.addEventListener("LazyLoad::Initialized",function(n){window.lazyLoadInstance=n.detail.instance},!1),document.addEventListener("DOMContentLoaded",function(){lazyLoadInstance.update()}),document.addEventListener("pjax:complete",function(){lazyLoadInstance.update()});</script><script>window.FPConfig={delay:0,ignoreKeywords:["#"],maxRPS:6,hoverDelay:0};</script><script defer="defer" src="https://cdn.jsdelivr.net/npm/mhg@0.0.1/js/flying-pages.min.js"></script><script>var APlayerController=new Object;APlayerController.id="412785957",APlayerController.volume="0.7",setTimeout(function(){loadCSS("https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.css",document.getElementById("loadcss")),loadScript("https://cdn.jsdelivr.net/npm/mhg@0.0.0/js/APlayer.mini.js"),loadScript("https://cdn.jsdelivr.net/npm/meting@2.0/dist/Meting.min.js")},1);</script><script>var load_minivaline,pjax_minivaline;"localhost"!=window.location.hostname&&(load_minivaline=function(){setTimeout(function(){loadScript("https://cdn.jsdelivr.net/npm/minivaline@4.2.3/dist/MiniValine.min.js",pjax_minivaline)},1)},pjax_minivaline=function(){var i,n,e;document.querySelectorAll("#minivaline_container")[0]&&(i=$.trim($("#pjax-comment-placeholder").text())||"快来评论吧~",0==(n=$.trim($("#pjax-comment-path").text())).length&&(n=decodeURI(window.location.pathname)),e="me.mhuig.top"==window.location.hostname||"dev.mhuig.top"==window.location.hostname?"https://mv.mhuig.top":"https://vmv.mhuig.top",new MiniValine({el:"#minivaline_container",appId:"233",appKey:"23333",mode:"xCss",placeholder:i,path:n,math:!0,md:!0,enableQQ:!1,NoRecordIP:!1,visitor:!0,maxNest:6,pageSize:6,barrager:0,closeFlag:!1,cloudflag:!0,closeUA:!1,serverURLs:e,region:"true"}))},$(function(){document.querySelectorAll("#minivaline_container")[0]&&load_minivaline()}));</script><script src="/js/app.js"></script><script>var ROOT="/".endsWith("/")?"/":"//";!function(){function n(){ustomSearch=new HexoSearch}jQuery(".input.u-search-input").one("focus",function(){loadScript("https://cdn.jsdelivr.net/npm/mhg@0.0.6/js/search.js",n)})}();</script><script>var ROOT="/".endsWith("/")?"/":"//";!function(){function n(){ustomSearch=new HexoSearch}jQuery(".input.u-search-input").one("focus",function(){loadScript("https://cdn.jsdelivr.net/npm/mhg@0.0.6/js/search.js",n)})}();</script><script>function _toConsumableArray(e){if(Array.isArray(e)){for(var t=0,n=Array(e.length);t<e.length;t++)n[t]=e[t];return n}return Array.from(e)}var TimeInterval,now=new Date;function SiteTime(){try{var e=new Date("08/19/2019 21:23:12");now.setTime(now.getTime()+250),days=(now-e)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-e)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-e)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-e)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="本站已安全运行 "+dnum+" 天 ",document.getElementById("times").innerHTML=hnum+" 小时 "+mnum+" 分 "+snum+" 秒"}catch(e){}}function listennSidebarTOC(){var i,c=document.querySelectorAll(".toc li");c.length&&(i=[].concat(_toConsumableArray(c)).map(function(e){var t=e.querySelector(".toc-link"),n=document.getElementById(decodeURI(t.getAttribute("href")).replace("#",""));return t.addEventListener("click",function(e){e.preventDefault(),window.scrollTo({top:n.offsetTop+100,behavior:"smooth"})}),n}),function r(a){a=Math.floor(a+1e4);var t=new IntersectionObserver(function(e,t){var n=document.documentElement.scrollHeight+100;if(a<n)return t.disconnect(),void r(n);var o=function(e){var t=0,n=e[t];if(0<n.boundingClientRect.top)return 0===(t=i.indexOf(n.target))?0:t-1;for(;t<e.length;t++){if(!(e[t].boundingClientRect.top<=0))return i.indexOf(n.target);n=e[t]}return i.indexOf(n.target)}(e);!function(e){if(!e.classList.contains("active-current")){document.querySelectorAll(".toc .active").forEach(function(e){e.classList.remove("active","active-current")}),e.classList.add("active","active-current");for(var t=e.parentNode;!t.matches(".toc");)t.matches("li")&&t.classList.add("active"),t=t.parentNode}}(c[o])},{rootMargin:a+"px 0px -100% 0px",threshold:0});i.forEach(function(e){e&&t.observe(e)})}(document.documentElement.scrollHeight))}"undefined"==typeof SiteTimeFlag&&(TimeInterval=setInterval("SiteTime()",250),window.SiteTimeFlag=!0),document.addEventListener("DOMContentLoaded",listennSidebarTOC),document.addEventListener("pjax:success",listennSidebarTOC),$(".darkbtn").parents(".header").on("click",function(e){window.darkmode.toggle(),window.darkmode.isActivated()?($(".darkbtn").removeClass("fa-moon"),$(".darkbtn").addClass("fa-sun")):($(".darkbtn").removeClass("fa-sun"),$(".darkbtn").addClass("fa-moon"))});var BlogPageTime=[],BlogPageURL=[];function getBlogPageTime(t,n){var o=(new Date).getTime();$.ajax({type:"HEAD",url:t,success:function(){var e=(new Date).getTime()-o;BlogPageTime.push(e),BlogPageURL.push(t),n()},error:function(){n()}})}function test(){var e=Math.min.apply(null,BlogPageTime),t=$.inArray(e,BlogPageTime);window.BlogPageFastURL=BlogPageURL[t],console.log(window.BlogPageFastURL)}function test1(){getBlogPageTime("https://mhuig.github.io",test)}function test2(){getBlogPageTime("https://me.mhuig.top",test1)}function test3(){getBlogPageTime("https://dev.mhuig.top",test2)}function click(e){document.all&&(2!=event.button&&3!=event.button||(oncontextmenu="return false")),document.layers&&3==e.which&&(oncontextmenu="return false")}getBlogPageTime("https://blog.mhuig.top",test3),window.location.hash&&document.getElementById(decodeURI(window.location.hash.split("#")[1]).replace(/\ /g,"-"))&&window.scrollTo(0,document.getElementById(decodeURI(window.location.hash.split("#")[1]).replace(/\ /g,"-")).offsetTop+100),setTimeout(function(){!function(){var e=document.createElement("script"),t=window.location.protocol.split(":")[0];e.src="https"===t?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",e.defer=!0;var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(e,n)}()},5e3),setInterval(function(){document.onselectstart=function(e){return!1},document.onselectstart=function(e){return!1},document.layers&&document.captureEvents(Event.MOUSEDOWN),document.onmousedown=click,document.oncontextmenu=new Function("return false;")},100);</script><script>loadScript("https://cdn.jsdelivr.net/npm/mhg@0.0.9/js/ip.min.js");</script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><div class="pjax-animate"><script aysc src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script><div id="loading-bar-wrapper"><script>NProgress.configure({parent:"#loading-bar-wrapper",trickleSpeed:100});</script></div><script>window.ShowLoading=function(){NProgress.start()},window.HideLoading=function(){NProgress.done()};</script></div><script>var pjax;document.addEventListener("DOMContentLoaded",function(){pjax=new Pjax({elements:'a[href]:not([href^="#"]):not([href="javascript:void(0)"]):not([pjax-fancybox])',selectors:["title","#pjax-container","#pjax-header-nav-list"],cacheBust:!1,timeout:5e3})}),document.addEventListener("pjax:send",function(e){try{var n=window.location.pathname,o=e.triggerElement.href,a=[""];""!=a[0]&&a.forEach(function(e){-1==n.indexOf(e)&&-1==o.indexOf(e)||(window.location.href=o)}),"localhost:4000"!=window.location.host&&window.location.origin&&window.BlogPageFastURL&&window.location.origin!=window.BlogPageFastURL&&(window.location.href=e.triggerElement.href.replace(window.location.origin,window.BlogPageFastURL))}catch(e){}window.subData=null,void 0!==$.fancybox&&$.fancybox.close(),$(".l_header .switcher .s-search").removeClass("active"),$(".l_header").removeClass("z_search-open"),$(".wrapper").removeClass("sub"),$(".s-top").unbind("click"),$(".menu a").unbind("click"),$(window).unbind("resize"),$(window).unbind("scroll"),$(document).unbind("scroll"),$(document).unbind("click"),$("body").unbind("click"),window.ShowLoading()}),document.addEventListener("pjax:complete",function(){_hmt.push(["_trackPageview",document.location.pathname]),window.dataLayer=window.dataLayer||[],function(){dataLayer.push(arguments)}("config","UA-148909894-1",{page_path:document.location.pathname}),$(".nav-main").find(".list-v").not(".menu-phone").removeAttr("style",""),$(".menu-phone.list-v").removeAttr("style",""),$("script[data-pjax], .pjax-reload script").each(function(){$(this).parent().append($(this).remove())});try{(void 0===$.fancybox?SCload_fancybox:pjax_fancybox)(),$(".cover-backstretch").backstretch("resize"),("undefined"==typeof MiniValine?load_minivaline:pjax_minivaline)(),pjax_darkmodejs(),"none"==document.getElementsByClassName("cover-wrapper")[0].style.display?$(".cover-backstretch").backstretch("pause"):$(".cover-backstretch").backstretch("next")}catch(e){console.log(e)}window.HideLoading()}),document.addEventListener("pjax:error",function(e){window.HideLoading(),window.location.href=e.triggerElement.href});</script></div><script>"serviceWorker"in navigator&&navigator.serviceWorker.register("/s.js").then(function(r){r.onupdatefound=function(){var e=r.installing;e.onstatechange=function(){switch(e.state){case"installed":navigator.serviceWorker.controller?console.log("Updated serviceWorker."):console.log("serviceWorker Sucess!");break;case"redundant":console.error("The installing service worker became redundant.")}}}}).catch(function(e){console.error("Error during service worker registration:",e)});</script></body></html>